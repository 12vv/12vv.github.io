---
title: A Parallel Task-based Approach to Linear Algebra 论文学习
date: 2019-05-18
tag: [Paper, Translation]
categories: [Paper]
---

## 简述

这是一篇[论文](https://ieeexplore.ieee.org/document/6900201/authors#authors)的翻译和学习。

<!--more-->

## 摘要
具有大量内核的处理器现已非常普遍。为了利用这些系统中的可用资源，编程必须朝着增加的并行性方向发展。但是，提高程序中的并发性并不一定会带来更好的性能。并行的编程模型必须提供定义并行任务的灵活方法，同时有效地管理创建的任务。 OpenMP是一个被广泛接受的共享内存架构模型。在本文中，我们重点介绍了OpenMP任务分配方法中的一些缺点，并提出了基于格拉斯哥并行约简机（GPRM）编程框架的替代模型。作为本研究的主要焦点，我们部署模型来解决基本线性代数问题，稀疏矩阵的LU因子分解。我们使用了BOTS基准测试套件中的SparseLU基准测试，并将从我们的模型获得的结果与OpenMP任务分配方法的结果进行了比较。 TILEPro64系统用于运行实验且结果十分可观，不仅因为这个特定问题的性能提高，而且验证了我们模型的任务管理效率，稳定性和灵活性，可用于解决未来多核系统中的问题。

## 引言

基于任务的并行编程模型正在迅速发展。随着多核处理器的出现，它们可以与数据并行方法竞争，同时由于其MIMD特性而提供更大的灵活性。一个任务是可以与其他任务并行运行的任何形式的计算(如果它们的数据依赖性允许)。大多数这些编程模型为程序员提供了一些关键字，用于在C / C ++等命令式语言中表示并行性。另一方面，纯函数式编程语言提供了原生并行性，但与主流语言（如C ++和Java）相比，它们都没有得到广泛采用。即使多核心编程语言被广泛采用，在短期内显然也不可能重写大量的单核遗留代码库，而且也不会有效率。因此，我们的任务是提出一种编程模型，该模型可以用命令式语言集成到现有代码中，同时提供与函数式语言类似的本机并行性。在详细介绍我们的方法 - 格拉斯哥并行减速机（GPRM）之前，我们想简要回顾一下市场上的一些可用型号，即Clojure，Chapel，Intel Cilk Plus，Intel Threading Building Blocks（TBB），和OpenMP。


并行编程并不像顺序编程那么简单。除了要考虑什么需要计算，程序员还需考虑如何协调计算。
Clojure [1]  - 也称为现代Lisp-是一种针对Java虚拟机（JVM）的函数式编程语言。 Clojure的语法基于S表达式，即第一个元素表示操作而其他元素表示操作数的列表。 GPRM使用类似的方法来表示其通信代码。

OpenCL [2]是异构架构的工业标准。它基本上定义了所有设备都支持的一组核心功能，并允许供应商公开更多的编程接口以及硬件功能。然而，它不像以下用于共享存储器架构的模型那样容易使用。

基于Cilk ++ [3]的英特尔Cilk Plus是C / C ++的一个扩展，它提供了任务和数据并行性。因其简洁而变得流行。它有_Cilk_spawn和_Cilk_sync关键字来生成和同步任务。 _Cilk_for循环是C / C ++中顺序循环的并行替换。 Intel Cilk Plus在程序开始时启动一个线程池，类似于GPRM线程池。

英特尔线程构建模块（TBB）是实现基于任务的并行性的另一种众所周知的方法[4]。 Intel TBB是一个面向对象的C ++运行时库，包含要在并行程序中使用的数据结构和算法。它抽象了低级别的线程细节，这与GPRM设计考虑类似。然而，任务带来了开销。将遗留代码转换为TBB需要重构程序的某些部分以适合TBB模板。 TBB优于OpenMP和Cilk Plus的是它不需要特定的编译器支持。

OpenMP可以称为共享内存架构中使用最广泛的编程标准。自OpenMP 3.0 [5]发布以来，可以通过OpenMP任务表达不规则的并行性。此外，与Cilk Plus和TBB相比，OpenMP在可预测的数据并行情况下运行良好。这使其成为诸如GPRM等新编程模型的具有挑战性的竞争者。我们在两种不同的场景中将GPRM的性能与OpenMP的性能进行了比较：首先是具有结构化并行性的微基准，其次是线性代数问题，它非常适合基于结构化程度低的基于任务的并行性。

在[6] - [9]中已经研究过OpenMP在细粒度任务(计算强度低)中表现不佳。它表明程序员有责任弄清楚特定输入参数的问题如何适合特定平台。作为一个常见的解决方案，程序员在创建OpenMP任务时使用截止值，以避免编写细粒度的任务。首先，找到合适的截止值并不简单，有时需要对程序进行全面分析。它通常取决于应用程序结构和输入数据集[10]。其次，仅在一些特殊情况下，例如递归，可以通过用户代码控制截止值。已经提出一个替代方案是将决定留给运行时系统。这个想法是通过不创建一些用户指定的任务而不是串行执行来聚合任务。在Nanos运行时系统中实现的自适应任务截止（ATC）[6]  - 一个研究OpenMP运行时系统 - 是一种根据程序执行早期收集的分析数据动态修改截止值的方案。然而，这根本不能在没有任何开销的情况下完成，而且需要扩展该方案以找到截止的所有情况。而在GPRM中有一种技术可以指定哪个任务最初将在哪个线程上运行。这大大减少了任务的开销。此外，还有一些工作共享结构可以与任务一起使用，以避免产生太多细粒度的任务。


[8]中介绍了任务粒度与OpenMP中任务数量之间的权衡。作者建议任务应该具有足够的粒度，并且随着消费者线程数量的增加，粒度应该增加。这是为了确保所有线程都忙着做一些有用的工作。他们还探讨了任务数量对负载平衡的影响，这意味着程序员必须在任务数量和粒度之间进行权衡，以获得较好的负载平衡，从而获得良好的性能。

在本文中，我们将展示OpenMP如何无法正常运行细粒度任务，而提出的模型能够应对这种情况（参见第V节）。此外，我们将引入混合工作共享任务方法，以避免创建太多任务（参见第VI节）。换句话说，将采用一种利用任务和数据并行性的混合方法来解决同构多核处理器上的LU分解问题。

稀疏矩阵的LU分解是一个基本的线性代数问题。由于矩阵的稀疏性，传统的工作共享解决方案是不够的，因为存在大量的负载不平衡。作为一个众所周知的测试用例，我们使用了Barcelona OpenMP Tasks Suite（BOTS）[11]中的SparseLU基准测试。在这个问题中，矩阵被组织成可能未被分配的块。更多信息以及源代码是公开可用的。

## GPRM
格拉斯哥并行约简机（GPRM）[9]为多核编程提供了一种基于任务的方法。程序员将程序结构化为任务代码，编写为C ++类，以及通信代码，编写在C ++的受限子集中。任务是表示S表达式的字节码列表，例如，`$(S_{1}(S_{2}10)20)$`表示具有两个参数的任务S1，第一参数是任务S2，且有数值常数10作为参数，S1第二参数是数值常数20。GPRM执行相应的字节码列表，同时评估函数参数。有关S表达式和字节码编译的更多详细信息，请参见[9]。用我们的说法，任务节点由任务内核和任务管理器组成。任务内核通常是一个复杂的，自包含的实体，为系统提供特定的功能，它本身并不知道系统的其余部分。任务内核具有运行到完成语义。相应的任务管理器提供内核的接口。计算任务内核被编写为C ++类。这意味着终端用户只需在GPRM::Kernel命名空间中创建类。

从概念上讲，GPRM由一组通过网络连接的`瓦片`组成。每个`瓦片`由一个任务节点和一个用于传入数据包的FIFO(First In First Out, 先进先出)队列组成。每个`瓦片`都在自己的线程中运行或在FIFO队列中阻塞。系统是事件驱动的，有两种可能的事件类型：数据包到达或任务内核生成的事件。后者可以是创建数据包，或是修改本地状态。即任务管理器(task manager,reduction engine)通过并行分派请求计算到其他区块的分组来评估字节码。

GPRM中的线程被视为执行资源。因此，对于每个处理核心，在自己的任务管理器都有一个线程。开始时，在实际程序启动之前创建一个线程池。引言中已经指出，GPRM提供了一种将任务与工作共享结构相结合的有效方法，以避免创建细粒度的任务。例如，不像在OpenMP任务方法[5]中常见的循环中创建任务，而是可以创建与GPRM中的并发级别一样多的任务，每个任务都有自己的索引。工作共享构造可以使用这些索引来指定循环的哪些元素属于哪个线程。并发级别定义为理论上可以在系统中同时运行的作业数。

通常，当任务相当时，通过选择并发级别与线程数相同可获得最佳结果，即GPRM中的核心数。虽然在第VI节中任务不相当，但作为解决方案，可以使用GPRM并行循环来平衡线程之间的负载。如将示出的，当使用中等大小或大的稀疏矩阵时，该解决方案非常有效。

## 平行化循环(PARALLEL LOOPS)

我们已经创建了许多用于GPRM的有用的并行循环结构。这些工作共享构造对应于OpenMP中的工作共享构造，在某种意义上它们用于在不同线程之间分配工作的不同部分。但是，他们执行操作的方式有很大差异。在OpenMP中，用户将循环标记为具有所需调度策略的OpenMP，并且OpenMP运行时决定哪些线程应该运行循环的哪个部分;在GPRM中，生成相同任务的多个实例 -- 通常与并发级别一样多 -- 每个实例具有不同的索引（类似于OpenCL中的global_id）。这些任务中的每一个都调用并行循环传递它们自己的索引，以指定它们的主线程应该执行哪些工作部分。

`par_for`结构用于并行化单个循环。它以`Round-Robin(循环制)`方式将作品分配给线程。 `par_nested_for`将嵌套循环视为单个循环，并遵循相同的模式来分发工作。或者，连续方法为每个线程提供$m/n$个块，并且余下$m％n$一个接一个地分配给最前面的线程。这些方法如图1所示，需要并行化嵌套循环，例如，在存在可变大小循环的情况下(第VI节中的SparseLU基准化)。

![](/images/multi/fig1.jpg)

![](/images/multi/li2.jpg)


GPRM 中的`par_for`和`par_nested_for`循环使用C ++模板和成员函数指针实现。`Listing1`和`Listing2`给出了这些工作共享结构的实现。默认情况下，它们将是我们的工作共享结构。连续并行循环具有类似的实现。我们将连续的并行循环表示为连续的 GPRM 方法。另一个有用的工作共享构造是并行嵌套循环。由于GPRM `par_nested_for`以最小的开销实现，因此它是一个非常有用的工作共享构造，我们将在下一节中看到。

## 实验环境设定(EXPERIMENTAL SETUP)

`Tilera TILEPro64`多核处理器(Tilera TILEPro64 Tile Processor)是一个32位VLIW多核，具有64个核心，通过多个8×8网状网络互连。默认情况下，它提供分布式缓存一致的共享内存。它有16GB的DDR内存，但为了使用所有核心共享的全局地址空间，寻址限制为32位，即4GB。它具有8KB的每核L1高速缓存和64KB的L2高速缓存。芯片上所有L2高速缓存的并集构成了分布式L3高速缓存。内核的工作频率为866MHz。在64个核心中，一个用于PCI通信，另外63个核心用于我们的实验。对于我们在本研究中的实验，我们使用了Tilera公司的MDE 3.0提供的tile-g ++编译器，它基于GCC版本4.4.3。已指定编译器标志`-O2`和`-std=c++ 0x`。值得一提的是，TILEPro64运行Tile Linux，它基于标准的开源Linux版本2.6.36。

## 矩阵的乘法微基准测试(MATRIX MULTIPLICATION MICRO-BENCHMARK)




## Ongoing



## 原文链接

[A Parallel Task-based Approach to Linear Algebra, Ashkan Tousimojarad & Wim Vanderbauwhede](https://ieeexplore.ieee.org/document/6900201/authors#authors)