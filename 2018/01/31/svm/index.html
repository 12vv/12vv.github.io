<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>svm理解 | INTERSTELLAR</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <meta name="keywords" content="Machine Learning">
  
  
  
  
  <meta name="description" content="简述在《统计学习方法》中，这样描述：  支持向量机（support vector machines，SVM）是一种二类分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，其学习策略便是间隔最大化，可形式化为一个凸二次规划（convex quadratic programming）问题的求解。">
<meta name="keywords" content="Machine Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="SVM理解">
<meta property="og:url" content="https://12vv.github.io/2018/01/31/svm/index.html">
<meta property="og:site_name" content="INTERSTELLAR">
<meta property="og:description" content="简述在《统计学习方法》中，这样描述：  支持向量机（support vector machines，SVM）是一种二类分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，其学习策略便是间隔最大化，可形式化为一个凸二次规划（convex quadratic programming）问题的求解。">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://12vv.github.io/images/svm/2-1.png">
<meta property="og:image" content="https://12vv.github.io/images/svm/2-2.png">
<meta property="og:image" content="https://12vv.github.io/images/svm/2-3.png">
<meta property="og:updated_time" content="2019-08-12T14:39:50.749Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SVM理解">
<meta name="twitter:description" content="简述在《统计学习方法》中，这样描述：  支持向量机（support vector machines，SVM）是一种二类分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，其学习策略便是间隔最大化，可形式化为一个凸二次规划（convex quadratic programming）问题的求解。">
<meta name="twitter:image" content="https://12vv.github.io/images/svm/2-1.png">
  
    <link rel="alternate" href="/atom.xml" title="INTERSTELLAR" type="application/atom+xml">
  

  

  <link rel="icon" href="/css/images/mylogo.jpg">
  <link rel="apple-touch-icon" href="/css/images/mylogo.jpg">
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
  <style type="text/css">
    @font-face{font-family:futura-pt; src:url("/css/fonts/FuturaPTBold.otf") format("woff");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt-light; src:url("/css/fonts/FuturaPTBook.otf") format("woff");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt-italic; src:url("/css/fonts/FuturaPTBookOblique.otf") format("woff");font-weight:400;font-style:italic;}
}

  </style>
  <link rel="stylesheet" href="/css/style.css">

  <script src="/js/jquery-3.1.1.min.js"></script>
  <script src="/js/bootstrap.js"></script>

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/css/bootstrap.css">

  
    <link rel="stylesheet" href="/css/dialog.css">
  

  

  
    <link rel="stylesheet" href="/css/header-post.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

  
  
  

</head>
</html>


  <body data-spy="scroll" data-target="#toc" data-offset="50">


  
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      
        <header>

    <div id="allheader" class="navbar navbar-default navbar-static-top" role="navigation">
        <div class="navbar-inner">
          
          <div class="container"> 
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>

            
              <a class="brand" style="
                 margin-top: 0px;" href="#" data-toggle="modal" data-target="#myModal">
                  <img width="124px" height="124px" alt="Hike News" src="/css/images/mylogo.jpg">
              </a>
            
            
            <div class="navbar-collapse collapse">
              <ul class="hnav navbar-nav">
                
                  <li> <a class="main-nav-link" href="/">Home</a> </li>
                
                  <li> <a class="main-nav-link" href="/archives">Archives</a> </li>
                
                  <li> <a class="main-nav-link" href="/categories">Categories</a> </li>
                
                  <li> <a class="main-nav-link" href="/tags">Tags</a> </li>
                
                  <li> <a class="main-nav-link" href="/about">About</a> </li>
                
                  <li><div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder>
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something...">
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div></li>
            </ul></div>
          </div>
                
      </div>
    </div>

</header>



      
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-svm" style="width: 75%; float:left;" class="article article-type-post" itemscope itemprop="blogPost">
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      SVM理解
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2018/01/31/svm/" class="article-date">
	  <time datetime="2018-01-31T16:00:00.000Z" itemprop="datePublished">2018-01-31</time>
	</a>

      
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>

      
	<a class="article-views">
	<span id="busuanzi_container_page_pv">
		PV:<span id="busuanzi_value_page_pv"></span>
	</span>
	</a>

      
	<a class="article-edit" target="_blank" rel="noopener" href="https://github.com/12vv/blog/edit/master/source/_posts/svm.md">
	<span id="edit">Edit</span>
	
	</a>


    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h2><p>在《统计学习方法》中，这样描述：</p>
<blockquote>
<p><code>支持向量机（support vector machines，SVM）</code>是一种二类分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，其学习策略便是间隔最大化，可形式化为一个<code>凸二次规划（convex quadratic programming）</code>问题的求解。</p>
</blockquote>
<a id="more"></a>
<h2 id="函数距离与几何距离"><a href="#函数距离与几何距离" class="headerlink" title="函数距离与几何距离"></a>函数距离与几何距离</h2><h3 id="函数间隔-function-margin"><a href="#函数间隔-function-margin" class="headerlink" title="函数间隔(function margin)"></a>函数间隔(function margin)</h3><p>对于给定训练数据集T和超平面$(w, b)$,定义超平面$(w,b)$关于样本点$(x_{i},y_{i})$的函数间隔为</p>
<script type="math/tex; mode=display">\widehat{\gamma_{i}}=y_{i}(w\cdot x_{i}+b)</script><p>定义超平面$(w,b)$关于数据集T的几何间隔为超平面$(w,b)$关于T中所有样本点$(x_{i},y_{i})$的函数间隔之最小值，即</p>
<script type="math/tex; mode=display">\widehat{\gamma}=min\widehat{\gamma _{i}}</script><h3 id="几何间隔-geimetric-margin"><a href="#几何间隔-geimetric-margin" class="headerlink" title="几何间隔(geimetric margin)"></a>几何间隔(geimetric margin)</h3><p>对于给定训练数据集T和超平面$(w, b)$,定义超平面$(w,b)$关于样本点<br>$(x_{i},y_{i})$的几何间隔为<script type="math/tex">\gamma_{i}=y_{i}(\frac{w}{\left \| w \right \|}\cdot x_{i}+\frac{b}{\left \| w \right \|})</script><br>定义超平面$(w,b)$关于数据集T的几何间隔为超平面$(w,b)$T中所有样本点$(x_{i},y_{i})$的几何间隔之最小值，即</p>
<script type="math/tex; mode=display">\gamma=min\gamma _{i}</script><p>因为如果超平面参数$w$和$b$成比例改变，虽然超平面不变，但是函数间隔离变了。因此使用几何间隔，并且令$\left | w \right |=1$，下图为《机器学习》中的一张插图。<br><img src="/images/svm/2-1.png" alt></p>
<h2 id="对偶问题"><a href="#对偶问题" class="headerlink" title="对偶问题"></a>对偶问题</h2><p>得到的目标函数如下</p>
<script type="math/tex; mode=display">max\frac{1}{\left \|w \right \|} \hspace{0.5cm} s.t., \gamma_{i}(w^{T}+b)\geq 1</script><p>由于求$\frac{1}{\left |w \right |}$的最大值相当于求$\frac{1}{2}\left |w \right |^{2}$的最小值，所以上面的目标函数等价于</p>
<script type="math/tex; mode=display">min\frac{1}{2}\left \|w \right \|^{2} \hspace{0.5cm} s.t., \gamma_{i}(w^{T}+b)\geq 1</script><hr>
<h3 id="补充解释"><a href="#补充解释" class="headerlink" title="补充解释"></a>补充解释</h3><blockquote>
<p>为了更好地理解接下来的内容，这里插入一段有关<code>对偶性(duality)</code>的补充。详情请见<a href="http://blog.pluskid.org/?p=702" target="_blank" rel="noopener">这篇文章</a>，已经清楚的伙伴可以跳过。</p>
</blockquote>
<p>简单来说，对于任意一个带约束的优化都可以写成这样的形式：</p>
<script type="math/tex; mode=display">
\begin{aligned} 
\min&f_0(x) \\ 
s.t. &f_i(x)\leq 0, \quad i=1,\ldots,m\\ 
&h_i(x)=0, \quad i=1,\ldots,p 
\end{aligned}</script><p>虽然约束条件能够帮助我们减小搜索空间，但是如果约束条件本身就是比较复杂的形式的话，其实是一件很让人头痛的问题，为此我们希望把带约束的优化问题转化为无约束的优化问题。为此，我们定义 <code>Lagrangian</code> 如下:</p>
<script type="math/tex; mode=display">L(x,\lambda,\nu)=f_0(x)+\sum_{i=1}^m\lambda_if_i(x)+\sum_{i=1}^p\nu_ih_i(x)</script><p>令：</p>
<script type="math/tex; mode=display">z(x)=\max_{\lambda\succeq 0, \nu}L(x,\lambda,\nu)</script><p>容易证明，对于满足约束条件的 x，有$f_0(x)=z(x)$，因为约束条件$h_i(x)=0$，即式子最后一项为0，又因为$\lambda\geq 0$且约束条件$f_i(x)\leq 0$，因此式子的第二项最大值为0，所以L的最大值即$z(x)=f_0(x)$.<br>所以，带约束条件的<code>原问题(primal problem)</code>转换为不带约束条件的优化问题，即：</p>
<script type="math/tex; mode=display">\min_x z(x)</script><p>也即(记为$p^*$)：</p>
<script type="math/tex; mode=display">p^*=\min_x\ \max_{\lambda\succeq 0, \nu} L(x, \lambda, \nu)</script><p>因为如果原始问题有最优值，那么肯定是在满足约束条件的某个 $x$ 取得，而对于所有满足约束条件的$ x$ ，$z(x)$ 和 $f_0(x)$ 都是相等的。<br>这个<code>原问题(primal problem)</code>的<code>对偶问题(dual problem)</code>将$min$和$max$调换了位置(记为$d^*$)：</p>
<script type="math/tex; mode=display">d^*=\max_{\lambda\succeq 0, \nu}\ \min_x L(x, \lambda, \nu)</script><p>可以证明$d^{*}\leq p^{<em>}$，此这个性质叫做<code>弱对偶(weak duality)</code> ，对于所有的优化问题都成立。注意，无论原问题是什么形式，它的对偶问题总是<code>凸优化问题(convex optimization)</code>。<br><code>强对偶(strong duality)</code>即$d^{</em>}=p^{*}$，在SVM中满足<code>KTT(Karush-Kuhn-Tucker)</code>条件，通过求解对偶问题间接求解原始问题。</p>
<hr>
<p>根据上面的补充，继续如下推导。<br>引入<code>拉格朗日乘子(Lagrange multiplier)</code>构造拉格朗日函数 ,( 其中拉格朗日乘子$\alpha=(\alpha_{1},\alpha_{2},…\alpha_{n})^{T}$ )</p>
<script type="math/tex; mode=display">L(w, b, \alpha)=\frac{1}{2}\left \|w \right \|^{2}-\sum_{i=1}^n\alpha_{i}(\gamma_{i}(w^{T}+b)-1)</script><p>要求解：</p>
<script type="math/tex; mode=display">\min_{w,b}\ \max_{\alpha_{i}\succeq 0} L(w, b, \alpha)=p^*</script><p>转换为对偶问题：</p>
<script type="math/tex; mode=display">\max_{\alpha_{i}\succeq 0}\ \min_{w,b}\  L(w, b, \alpha)=d^*</script><h3 id="对偶问题求解"><a href="#对偶问题求解" class="headerlink" title="对偶问题求解"></a>对偶问题求解</h3><blockquote>
<p>先求$L(w, b, \alpha)$对 $w$,$b$的极小，再求对$\alpha$的极大。</p>
</blockquote>
<p>求$\min_{w,b}\  L(w, b, \alpha)$ ：将拉格朗日函数$L(w, b, \alpha)$分别对$w$,$b$求偏导数并令其等于0。</p>
<script type="math/tex; mode=display">\nabla_{w}L(w, b, \alpha)=0 \hspace{0.6cm}和 \hspace{0.6cm} \nabla_{b}L(w, b, \alpha)=0</script><p>得到</p>
<script type="math/tex; mode=display">w=\sum_{i=1}^n\alpha_{i}y_{i}x_{i} \hspace{0.6cm}和 \hspace{0.6cm}\sum_{i=1}^n\alpha_{i}y_{i}=0</script><p>将上面两式带入拉格朗日函数L，得到：</p>
<script type="math/tex; mode=display">\min_{w,b}\  L(w, b, \alpha)=-\frac{1}{2}\sum_{i,j=1}^n\alpha_{i}\alpha_{j}y_{i}y_{j}x_{i}^Tx_{j}+\sum_{i=1}^n\alpha_{i}</script><p>详细推导补充如下：</p>
<p><img src="/images/svm/2-2.png" alt></p>
<p><img src="/images/svm/2-3.png" alt></p>
<p>接下来求$\min_{w,b}\  L(w, b, \alpha)$对 $\alpha$的极大</p>
<script type="math/tex; mode=display">max-\frac{1}{2}\sum_{i,j=1}^n\alpha_{i}\alpha_{j}y_{i}y_{j}x_{i}^Tx_{j}+\sum_{i=1}^n\alpha_{i} \\ s.t.,\ \alpha_{i}\geq 0, i=1,...,n \\ \sum_{i=1}^n\alpha_{i}y_{i}=0</script><p>将 $\alpha^{*}=(\alpha_{1},\alpha_{2},…\alpha_{n})^{T}$ 求解出来之后，即可求出 $w^{*}$ 和 $b^{*}$</p>
<script type="math/tex; mode=display">w^{*}=\sum_{i=1}^n\alpha_{i}y_{i}x_{i}</script><script type="math/tex; mode=display">b^{\*}=y_{i}- \sum_{i=1}^n \alpha_{i}^{*}y_{i}(x_{i} \cdot x_{j})</script><p>二次规划求解可以使用更加优化的<code>SMO(Sequential Minimal Optimization)</code>替代，更加高效，暂时自己还没有看懂，先放着。</p>
<h3 id="Kernels"><a href="#Kernels" class="headerlink" title="Kernels"></a>Kernels</h3><p>当数据在当前维度(<code>or features</code>)不是线性可分的，我们想要进行如下转换</p>
<blockquote>
<p>for vector $\mathbf{x}\in\mathbb{R}^d$, apply transformation $\mathbf{x} \rightarrow \phi(\mathbf{x})$ where $\phi(\mathbf{x})\in\mathbb{R}^D$, usually $D \gg d$。</p>
</blockquote>
<script type="math/tex; mode=display">
\mathbf{x}=\begin{pmatrix}x_1\\ x_2\\ \vdots \\ x_d \end{pmatrix} \;\;\;\phi(\mathbf{x})=\begin{pmatrix}1\\ x_1\\ \vdots \\x_d \\ x_1x_2 \\ \vdots \\ x_{d-1}x_d\\ \vdots \\x_1x_2\cdots x_d \end{pmatrix}</script><p>这样$\phi(x)$的维度达到了$2^d$，难以计算。</p>
<h4 id="The-Kernel-Trick"><a href="#The-Kernel-Trick" class="headerlink" title="The Kernel Trick"></a>The Kernel Trick</h4><h5 id="Gradient-Descent-with-Squared-Loss"><a href="#Gradient-Descent-with-Squared-Loss" class="headerlink" title="Gradient Descent with Squared Loss"></a>Gradient Descent with Squared Loss</h5><script type="math/tex; mode=display">
\ell(\mathbf{w}) = \sum_{i=1}^n (\mathbf{w}^\top  \mathbf{x}_i-y_i)^2</script><p>使用梯度下降更新得到</p>
<script type="math/tex; mode=display">
w_{t+1} \leftarrow w_t - s(\frac{\partial \ell}{\partial \mathbf{w}})\  where: 
  \frac{\partial \ell}{\partial \mathbf{w}}=\sum_{i=1}^n2(w^Tx_i-y_i)x_i=\sum_{i=1}^n\gamma_i \mathbf{x}_i</script><p>把$w$表示成所有<code>input vector x</code>的线性组合：</p>
<script type="math/tex; mode=display">
  \mathbf{w}=\sum_{i=1}^n \alpha_i {\mathbf{x}}_i</script><p>因为损失是凸函数，结果与初始点的选取无关，方便起见取$\mathbf{w}_0=\begin{pmatrix}0 \\ \vdots \\ 0\end{pmatrix}$</p>
<script type="math/tex; mode=display">

\mathbf{w}_1=\mathbf{w}_0-s\sum_{i=1}^n2(\mathbf{w}_0^\top  \mathbf{x}_i-y_i)\mathbf{x}_i=\sum_{i=1}^n \alpha_i^0 {\mathbf{x}}_i-s\sum_{i=1}^n\gamma_i^0\mathbf{x}_i=\sum_{i=1}^n\alpha_i^1\mathbf{x}_i

(with \;\;\;  \alpha_i^1=\alpha_i^0-s\gamma_i^0)


\mathbf{w}_2=\mathbf{w}_1-s\sum_{i=1}^n2(\mathbf{w}_1^\top  \mathbf{x}_i-y_i)\mathbf{x}_i=\sum_{i=1}^n \alpha_i^1\mathbf{x}_i-s\sum_{i=1}^n\gamma_i^1\mathbf{x}_i=\sum_{i=1}^n\alpha_i^2\mathbf{x}_i

(with \;\;\;\alpha_i^2=\alpha_i^1\mathbf{x}_i-s\gamma_i^1)


\mathbf{w}_3=\mathbf{w}_2-s\sum_{i=1}^n2(\mathbf{w}_2^\top  \mathbf{x}_i-y_i)\mathbf{x}_i=\sum_{i=1}^n \alpha_i^2\mathbf{x}_i-s\sum_{i=1}^n\gamma_i^2\mathbf{x}_i=\sum_{i=1}^n\alpha_i^3\mathbf{x}_i

(with \;\;\;\alpha_i^3=\alpha_i^2-s\gamma_i^2)

... \qquad\qquad\qquad ... 


\mathbf{w}_t=\mathbf{w}_{t-1}-s\sum_{i=1}^n2(\mathbf{w}_{t-1}^\top  \mathbf{x}_i-y_i)\mathbf{x}_i=\sum_{i=1}^n \alpha_i^{t-1}\mathbf{x}_i-s\sum_{i=1}^n\gamma_i^{t-1}\mathbf{x}_i=\sum_{i=1}^n\alpha_i^t\mathbf{x}_i

(with \;\;\;\alpha_i^t=\alpha_i^{t-1}-s\gamma_i^{t-1})</script><p>数学归纳法得出$\alpha$的更新规则</p>
<script type="math/tex; mode=display">
\alpha_i^t=\alpha_i^{t-1}-s\gamma_i^{t-1}, 


\alpha_i^t=-s\sum_{r=0}^{t-1}\gamma_i^{r}.</script><p>就可以把计算高维度<code>w</code>的任务转换成$x$的内积。</p>
<script type="math/tex; mode=display">
\mathbf{w}^\top {\mathbf{x}}_j=\sum_{i=1}^n \alpha_i {\mathbf{x}}_i^\top{\mathbf{x}}_j</script><p>损失函数变为:</p>
<script type="math/tex; mode=display">
\ell(\mathbf{\alpha}) = \sum_{i=1}^n \left(\sum_{j=1}^n\alpha_j\mathbf{x}_j^\top  \mathbf{x}_i-y_i\right)^2</script><p>计算内积的<code>trick</code>。<br>The sum of $2^d$ terms becomes the product of <code>d</code> terms. </p>
<script type="math/tex; mode=display">
\phi(\mathbf{x})^\top \phi(\mathbf{z})=1\cdot 1+x_1z_1+x_2z_2+\cdots +x_1x_2z_1z_2+ \cdots +x_1\cdots x_dz_1\cdots z_d=\prod_{k=1}^d(1+x_kz_k)</script><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>个人感觉SVM挺难理解的，前前后后参考了很多资料，感谢大神们的总结和指导，自己仍有不足，若有错漏欢迎指出。有引用部分，侵删。<br>参考如下：</p>
<ol>
<li><a href="https://blog.csdn.net/v_july_v/article/details/7624837" target="_blank" rel="noopener">SVM三重境界</a></li>
<li>《统计学习方法》 李航</li>
<li><a href="http://blog.pluskid.org/?p=702" target="_blank" rel="noopener">支持向量机：Duality</a></li>
<li>《机器学习》 周志华</li>
<li>[cornellCS4780/CS5780] (<a href="http://www.cs.cornell.edu/courses/cs4780/2018fa/syllabus/index.html" target="_blank" rel="noopener">http://www.cs.cornell.edu/courses/cs4780/2018fa/syllabus/index.html</a>)</li>
</ol>

      
    </div>
    <footer class="article-footer">
      
      
      <div>
        <ul class="post-copyright">
          <li class="post-copyright-author">
          <strong>Post author:  </strong>Jaythan
          </li>
          <li class="post-copyright-link">
          <strong>Post link:  </strong>
          <a href="/2018/01/31/svm/" target="_blank" title="SVM理解">https://12vv.github.io/2018/01/31/svm/</a>
          </li>
          <li class="post-copyright-license">
            <strong>Copyright Notice:   </strong>
            All articles in this blog are licensed under <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">CC BY-NC-ND 4.0</a>
            unless stating additionally.
          </li>
         
        </ul>
<div>
</div></div>
      
      
      
        
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li></ul>

      

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/02/04/distribution/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          一些常见的分布
        
      </div>
    </a>
  
  
    <a href="/2018/01/01/vc_dimension/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">VC-Dimension</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="toc-sidebar">
    <div id="toc" class="toc-article">
    <strong class="toc-title">Contents</strong>
    
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#简述"><span class="nav-text">简述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#函数距离与几何距离"><span class="nav-text">函数距离与几何距离</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#函数间隔-function-margin"><span class="nav-text">函数间隔(function margin)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#几何间隔-geimetric-margin"><span class="nav-text">几何间隔(geimetric margin)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#对偶问题"><span class="nav-text">对偶问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#补充解释"><span class="nav-text">补充解释</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#对偶问题求解"><span class="nav-text">对偶问题求解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kernels"><span class="nav-text">Kernels</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#The-Kernel-Trick"><span class="nav-text">The Kernel Trick</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Gradient-Descent-with-Squared-Loss"><span class="nav-text">Gradient Descent with Squared Loss</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考资料"><span class="nav-text">参考资料</span></a></li></ol>
    
    </div>
  </aside>

</section>
        
      </div>
      
      <footer id="footer">
  

  <div class="container">
      	<div class="row">
	      <p> Powered by <a href="https://12vv.github.io" target="_blank">Jay‘s Cat</a>  </p>
	      <p id="copyRightEn">Copyright &copy; 2018 - 2021 INTERSTELLAR All Rights Reserved.</p>
	      

		</div>

		
  </div>
</footer>


<!-- min height -->

<script>
    var wrapdiv = document.getElementById("wrap");
    var contentdiv = document.getElementById("content");
    var allheader = document.getElementById("allheader");

    wrapdiv.style.minHeight = document.body.offsetHeight + "px";
    if (allheader != null) {
      contentdiv.style.minHeight = document.body.offsetHeight - allheader.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    } else {
      contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    }
</script>
    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/scripts.js"></script>




  <script src="/js/dialog.js"></script>









	<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
	</script>






  </div>

  <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true" style="display: none;">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h2 class="modal-title" id="myModalLabel">设置</h2>
      </div>
      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">


      <div class="modal-body">
          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" onclick="javascript:setFontSize();" aria-expanded="true" aria-controls="collapseOne">
              正文字号大小
            </a>
          </div>
          <div id="collapseOne" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingOne">
          <div class="panel-body">
            您已调整页面字体大小
          </div>
        </div>
      


          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" onclick="javascript:setBackground();" aria-expanded="true" aria-controls="collapseTwo">
              夜间护眼模式
            </a>
        </div>
          <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
          <div class="panel-body">
            夜间模式已经开启，再次单击按钮即可关闭 
          </div>
        </div>

        <div>
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="true" aria-controls="collapseThree">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关 于&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
         <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
          <div class="panel-body">
            INTERSTELLAR
          </div>
          <div class="panel-body">
            Copyright © 2021 Jaythan All Rights Reserved.
          </div>
        </div>
      </div>


      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <div class="modal-footer">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
      </div>
    </div>
  </div>
</div>
  
  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
  
    <a id="menu-switch"><i class="fa fa-bars fa-lg"></i></a><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src>
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  
</body>
</html>